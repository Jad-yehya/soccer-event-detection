{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL9De6TFvJ5K"
      },
      "source": [
        "# Vector Quantized VAE (VQ-VAE) implementation from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9WGGM0IvJ5M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from PIL import Image\n",
        "Image.LOAD_TRUNCATED_IMAGES = True\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from tqdm.notebook import tqdm\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHRqt54DvJ5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06cdcb1-7eeb-4f13-e7e0-7820cc0ca33e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqL6k_HUvJ5N"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, kernel_size=(4, 4, 3, 1), stride=2):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        kernel_1, kernel_2, kernel_3, kernel_4 = kernel_size\n",
        "\n",
        "        self.strided_conv_1 = nn.Conv2d(input_dim, hidden_dim, kernel_1, stride, padding=1)\n",
        "        self.strided_conv_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_2, stride, padding=1)\n",
        "\n",
        "        self.residual_conv_1 = nn.Conv2d(hidden_dim, hidden_dim, kernel_3, padding=1)\n",
        "        self.residual_conv_2 = nn.Conv2d(hidden_dim, output_dim, kernel_4, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.strided_conv_1(x)\n",
        "        x = self.strided_conv_2(x)\n",
        "\n",
        "        x = nn.functional.relu(x)\n",
        "        y = self.residual_conv_1(x)\n",
        "        y += x\n",
        "\n",
        "        x = nn.functional.relu(y)\n",
        "        y = self.residual_conv_2(x)\n",
        "        y += x\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZC5fYnTvJ5N"
      },
      "outputs": [],
      "source": [
        "class VQEmbeddingEMA(nn.Module):\n",
        "    def __init__(self, n_embeddings, embedding_dim, commitment_cost=0.25, decay=0.999, epsilon=1e-5):\n",
        "        super(VQEmbeddingEMA, self).__init__()\n",
        "        self.commitment_cost = commitment_cost\n",
        "        self.decay = decay\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        init_bound = 1 / n_embeddings\n",
        "        embedding = torch.Tensor(n_embeddings, embedding_dim)\n",
        "        embedding.uniform_(-init_bound, init_bound)\n",
        "        self.register_buffer(\"embedding\", embedding)\n",
        "        self.register_buffer(\"ema_count\", torch.zeros(n_embeddings))\n",
        "        self.register_buffer(\"ema_weight\", self.embedding.clone())\n",
        "\n",
        "    def encode(self, x):\n",
        "        M, D = self.embedding.size()\n",
        "        x_flat = x.detach().reshape(-1, D)\n",
        "\n",
        "        distances = torch.addmm(torch.sum(self.embedding ** 2, dim=1) +\n",
        "                    torch.sum(x_flat ** 2, dim=1, keepdim=True),\n",
        "                                x_flat, self.embedding.t(),\n",
        "                                alpha=-2.0, beta=1.0)\n",
        "\n",
        "        indices = torch.argmin(distances.float(), dim=-1)\n",
        "        quantized = nn.functional.embedding(indices, self.embedding)\n",
        "        quantized = quantized.view_as(x)\n",
        "        return quantized, indices.view(x.size(0), x.size(1))\n",
        "\n",
        "    def retrieve_random_codebook(self, random_indices):\n",
        "        quantized = nn.functional.embedding(random_indices, self.embedding)\n",
        "        quantized = quantized.transpose(1, 3)\n",
        "\n",
        "        return quantized\n",
        "\n",
        "    def forward(self, x):\n",
        "        M, D = self.embedding.size()\n",
        "        x_flat = x.detach().reshape(-1, D)\n",
        "\n",
        "        distances = torch.addmm(torch.sum(self.embedding ** 2, dim=1) +\n",
        "                                torch.sum(x_flat ** 2, dim=1, keepdim=True),\n",
        "                                x_flat, self.embedding.t(),\n",
        "                                alpha=-2.0, beta=1.0)\n",
        "\n",
        "        indices = torch.argmin(distances.float(), dim=-1)\n",
        "        encodings = nn.functional.one_hot(indices, M).float()\n",
        "        quantized = nn.functional.embedding(indices, self.embedding)\n",
        "        quantized = quantized.view_as(x)\n",
        "\n",
        "        if self.training:\n",
        "            self.ema_count = self.decay * self.ema_count + (1 - self.decay) * torch.sum(encodings, dim=0)\n",
        "            n = torch.sum(self.ema_count)\n",
        "            self.ema_count = (self.ema_count + self.epsilon) / (n + M * self.epsilon) * n\n",
        "\n",
        "            dw = torch.matmul(encodings.t(), x_flat)\n",
        "            self.ema_weight = self.decay * self.ema_weight + (1 - self.decay) * dw\n",
        "            self.embedding = self.ema_weight / self.ema_count.unsqueeze(-1)\n",
        "\n",
        "        codebook_loss = nn.functional.mse_loss(x.detach(), quantized)\n",
        "        e_latent_loss = nn.functional.mse_loss(x, quantized.detach())\n",
        "        commitment_loss = self.commitment_cost * e_latent_loss\n",
        "\n",
        "        quantized = x + (quantized - x).detach()\n",
        "\n",
        "        avg_probs = torch.mean(encodings, dim=0)\n",
        "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
        "\n",
        "        return quantized, commitment_loss, codebook_loss, perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KvbRJfNvJ5O"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, kernel_sizes=(1, 3, 2, 2), stride=2):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        kernel_1, kernel_2, kernel_3, kernel_4 = kernel_sizes\n",
        "\n",
        "        self.residual_conv_1 = nn.Conv2d(input_dim, hidden_dim, kernel_1, padding=0)\n",
        "        self.residual_conv_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_2, padding=1)\n",
        "\n",
        "        self.strided_t_conv_1 = nn.ConvTranspose2d(hidden_dim, hidden_dim, kernel_3, stride, padding=0)\n",
        "        self.strided_t_conv_2 = nn.ConvTranspose2d(hidden_dim, output_dim, kernel_4, stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.residual_conv_1(x)\n",
        "        y += x\n",
        "        x = nn.functional.relu(y)\n",
        "\n",
        "        y = self.residual_conv_2(x)\n",
        "        y += x\n",
        "        y = nn.functional.relu(y)\n",
        "\n",
        "        y = self.strided_t_conv_1(y)\n",
        "        y = self.strided_t_conv_2(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJPFO_JDvJ5P"
      },
      "outputs": [],
      "source": [
        "class VQVAE(nn.Module):\n",
        "    def __init__(self, Encoder, Codebook, Decoder):\n",
        "        super(VQVAE, self).__init__()\n",
        "        self.encoder = Encoder\n",
        "        self.codebook = Codebook\n",
        "        self.decoder = Decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        z_quantized, commitment_loss, codebook_loss, perplexity = self.codebook(z)\n",
        "        x_hat = self.decoder(z_quantized)\n",
        "\n",
        "        return x_hat, commitment_loss, codebook_loss, perplexity\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5tArF8zvJ5P"
      },
      "outputs": [],
      "source": [
        "input_dim = 3\n",
        "hidden_dim = 64\n",
        "#latent_dim = 64\n",
        "n_embeddings = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8331C4vMvJ5P"
      },
      "outputs": [],
      "source": [
        "encode = Encoder(input_dim, hidden_dim, hidden_dim)\n",
        "codebook = VQEmbeddingEMA(n_embeddings, hidden_dim)\n",
        "decode = Decoder(hidden_dim, hidden_dim, input_dim)\n",
        "\n",
        "model = VQVAE(encode, codebook, decode).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYuzs39vJ5P"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "mse_loss = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nW3GzNuvJ5Q"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "print_step = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tepb_cJvJ5Q"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112,112)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIKyEHuNvkSi",
        "outputId": "85914fc3-c58f-4971-8665-e8681f4859a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5r1EGA4vf3d"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "  zip_ref = zipfile.ZipFile('/content/drive/MyDrive/trial.zip', 'r')\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW4GusTSvJ5Q"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(\"./trial/\", transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v4JmP70vJ5Q"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)/4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA0uJrdm8TPS",
        "outputId": "4fa8e193-08e1-43ed-9586-1aede87800e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq7k5-l1vJ5Q"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, loss, perplexity, recon_loss, codebook_loss, filename):\n",
        "    state = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"loss\": loss,\n",
        "        \"perplexity\": perplexity,\n",
        "        \"recon_loss\": recon_loss,\n",
        "        \"codebook_loss\": codebook_loss\n",
        "    }\n",
        "    torch.save(state, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bbad5c04323042a19364135081b2e440",
            "cbf83620613d4dedafdfdd8a6cf9d56f",
            "e23f0a51466e4e55ac69ca72d05307a1",
            "4d0ef1f8c21a4f8394d54a831f83063b",
            "365cd66714f5460398f3493d08cf1e2e",
            "a33937380e6b44cf8a05a838dbc2ab1b",
            "6ccaf82b0e3049ed8a8eef14c7001203",
            "e5a93c93e1a54852a4986548947ba2eb",
            "e311b0aa5e0849efbeb1481155d2a7f8",
            "33e760c100af4eaab2f66641f3a51b08",
            "b4dd2aa1d3ac47c2a31925112289697b"
          ]
        },
        "id": "QqSS2rFGvJ5R",
        "outputId": "47fd9371-c95e-4b81-bc36-9be949780665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training VQ-VAE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbad5c04323042a19364135081b2e440"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1   step: 1   recon_loss: 0.1866087019443512   perplexity:  36.73640060424805 \n",
            "\t\tcommit_loss:  0.0044831084087491035   codebook loss:  0.017932433634996414   total_loss:  0.20902423560619354\n",
            "epoch: 1   step: 101   recon_loss: 0.015706485137343407   perplexity:  182.4307098388672 \n",
            "\t\tcommit_loss:  0.01364827249199152   codebook loss:  0.05459308996796608   total_loss:  0.08394785225391388\n",
            "epoch: 1   step: 201   recon_loss: 0.014088070951402187   perplexity:  289.3202819824219 \n",
            "\t\tcommit_loss:  0.015485777519643307   codebook loss:  0.06194311007857323   total_loss:  0.09151695668697357\n",
            "epoch: 1   step: 301   recon_loss: 0.011030398309230804   perplexity:  334.3252258300781 \n",
            "\t\tcommit_loss:  0.016161199659109116   codebook loss:  0.06464479863643646   total_loss:  0.09183639287948608\n",
            "epoch: 1   step: 401   recon_loss: 0.010862873867154121   perplexity:  373.29534912109375 \n",
            "\t\tcommit_loss:  0.01920594833791256   codebook loss:  0.07682379335165024   total_loss:  0.10689261555671692\n",
            "epoch: 2   step: 1   recon_loss: 0.010547204874455929   perplexity:  385.1072082519531 \n",
            "\t\tcommit_loss:  0.02004866860806942   codebook loss:  0.08019467443227768   total_loss:  0.11079055070877075\n",
            "epoch: 2   step: 101   recon_loss: 0.008811857551336288   perplexity:  377.9781494140625 \n",
            "\t\tcommit_loss:  0.01886734925210476   codebook loss:  0.07546939700841904   total_loss:  0.10314860194921494\n",
            "epoch: 2   step: 201   recon_loss: 0.009525116533041   perplexity:  402.5429382324219 \n",
            "\t\tcommit_loss:  0.020222678780555725   codebook loss:  0.0808907151222229   total_loss:  0.11063851416110992\n",
            "epoch: 2   step: 301   recon_loss: 0.009861688129603863   perplexity:  407.0996398925781 \n",
            "\t\tcommit_loss:  0.019607121124863625   codebook loss:  0.0784284844994545   total_loss:  0.10789729654788971\n",
            "epoch: 2   step: 401   recon_loss: 0.009295851923525333   perplexity:  423.2669982910156 \n",
            "\t\tcommit_loss:  0.02143939398229122   codebook loss:  0.08575757592916489   total_loss:  0.11649282276630402\n",
            "epoch: 3   step: 1   recon_loss: 0.008185338228940964   perplexity:  398.2747802734375 \n",
            "\t\tcommit_loss:  0.018226880580186844   codebook loss:  0.07290752232074738   total_loss:  0.09931974112987518\n",
            "epoch: 3   step: 101   recon_loss: 0.008010718040168285   perplexity:  396.5028381347656 \n",
            "\t\tcommit_loss:  0.01893947832286358   codebook loss:  0.07575791329145432   total_loss:  0.1027081087231636\n",
            "epoch: 3   step: 201   recon_loss: 0.007979865185916424   perplexity:  406.12750244140625 \n",
            "\t\tcommit_loss:  0.019049635156989098   codebook loss:  0.07619854062795639   total_loss:  0.10322804003953934\n",
            "epoch: 3   step: 301   recon_loss: 0.007212795317173004   perplexity:  386.9752197265625 \n",
            "\t\tcommit_loss:  0.017817918211221695   codebook loss:  0.07127167284488678   total_loss:  0.09630239009857178\n",
            "epoch: 3   step: 401   recon_loss: 0.008108876645565033   perplexity:  411.07611083984375 \n",
            "\t\tcommit_loss:  0.019768793135881424   codebook loss:  0.0790751725435257   total_loss:  0.10695284605026245\n",
            "epoch: 4   step: 1   recon_loss: 0.008165095001459122   perplexity:  401.8713073730469 \n",
            "\t\tcommit_loss:  0.018929699435830116   codebook loss:  0.07571879774332047   total_loss:  0.10281359404325485\n",
            "epoch: 4   step: 101   recon_loss: 0.008034387603402138   perplexity:  409.9648132324219 \n",
            "\t\tcommit_loss:  0.01968555524945259   codebook loss:  0.07874222099781036   total_loss:  0.10646216571331024\n",
            "epoch: 4   step: 201   recon_loss: 0.008063334040343761   perplexity:  398.34332275390625 \n",
            "\t\tcommit_loss:  0.01949223130941391   codebook loss:  0.07796892523765564   total_loss:  0.10552449524402618\n",
            "epoch: 4   step: 301   recon_loss: 0.007656634785234928   perplexity:  392.8275146484375 \n",
            "\t\tcommit_loss:  0.018348053097724915   codebook loss:  0.07339221239089966   total_loss:  0.09939689934253693\n",
            "epoch: 4   step: 401   recon_loss: 0.007525507360696793   perplexity:  395.7231140136719 \n",
            "\t\tcommit_loss:  0.018249066546559334   codebook loss:  0.07299626618623734   total_loss:  0.09877084195613861\n",
            "epoch: 5   step: 1   recon_loss: 0.007545659318566322   perplexity:  400.9147033691406 \n",
            "\t\tcommit_loss:  0.018570812419056892   codebook loss:  0.07428324967622757   total_loss:  0.10039971768856049\n",
            "epoch: 5   step: 101   recon_loss: 0.00806009117513895   perplexity:  407.2002258300781 \n",
            "\t\tcommit_loss:  0.019366111606359482   codebook loss:  0.07746444642543793   total_loss:  0.10489064455032349\n",
            "epoch: 5   step: 201   recon_loss: 0.0072089917957782745   perplexity:  397.12005615234375 \n",
            "\t\tcommit_loss:  0.01739562675356865   codebook loss:  0.0695825070142746   total_loss:  0.09418712556362152\n",
            "epoch: 5   step: 301   recon_loss: 0.007729529403150082   perplexity:  402.2904052734375 \n",
            "\t\tcommit_loss:  0.018765322864055634   codebook loss:  0.07506129145622253   total_loss:  0.10155614465475082\n",
            "epoch: 5   step: 401   recon_loss: 0.00795552134513855   perplexity:  418.6942138671875 \n",
            "\t\tcommit_loss:  0.01989954710006714   codebook loss:  0.07959818840026855   total_loss:  0.10745325684547424\n",
            "epoch: 6   step: 1   recon_loss: 0.00757649214938283   perplexity:  389.20233154296875 \n",
            "\t\tcommit_loss:  0.018097272142767906   codebook loss:  0.07238908857107162   total_loss:  0.09806285053491592\n",
            "epoch: 6   step: 101   recon_loss: 0.0070586740039289   perplexity:  404.4517517089844 \n",
            "\t\tcommit_loss:  0.01800578646361828   codebook loss:  0.07202314585447311   total_loss:  0.09708760678768158\n",
            "epoch: 6   step: 201   recon_loss: 0.006801941432058811   perplexity:  375.9846496582031 \n",
            "\t\tcommit_loss:  0.016674602404236794   codebook loss:  0.06669840961694717   total_loss:  0.09017495810985565\n",
            "epoch: 6   step: 301   recon_loss: 0.007969550788402557   perplexity:  424.4151611328125 \n",
            "\t\tcommit_loss:  0.019669262692332268   codebook loss:  0.07867705076932907   total_loss:  0.10631586611270905\n",
            "epoch: 6   step: 401   recon_loss: 0.006723153404891491   perplexity:  384.7703857421875 \n",
            "\t\tcommit_loss:  0.016954412683844566   codebook loss:  0.06781765073537827   total_loss:  0.09149521589279175\n",
            "epoch: 7   step: 1   recon_loss: 0.007625950966030359   perplexity:  413.60595703125 \n",
            "\t\tcommit_loss:  0.018831519410014153   codebook loss:  0.07532607764005661   total_loss:  0.10178354382514954\n",
            "epoch: 7   step: 101   recon_loss: 0.007263718638569117   perplexity:  405.3537902832031 \n",
            "\t\tcommit_loss:  0.018117215484380722   codebook loss:  0.07246886193752289   total_loss:  0.09784979373216629\n",
            "epoch: 7   step: 201   recon_loss: 0.0071384175680577755   perplexity:  399.3050231933594 \n",
            "\t\tcommit_loss:  0.017816264182329178   codebook loss:  0.07126505672931671   total_loss:  0.0962197408080101\n",
            "epoch: 7   step: 301   recon_loss: 0.006806276272982359   perplexity:  395.6152038574219 \n",
            "\t\tcommit_loss:  0.017271170392632484   codebook loss:  0.06908468157052994   total_loss:  0.09316212683916092\n",
            "epoch: 7   step: 401   recon_loss: 0.006877584382891655   perplexity:  388.0121765136719 \n",
            "\t\tcommit_loss:  0.016888553276658058   codebook loss:  0.06755421310663223   total_loss:  0.09132035076618195\n",
            "epoch: 8   step: 1   recon_loss: 0.007231066469103098   perplexity:  406.8042907714844 \n",
            "\t\tcommit_loss:  0.01851838268339634   codebook loss:  0.07407353073358536   total_loss:  0.0998229831457138\n",
            "epoch: 8   step: 101   recon_loss: 0.006419316399842501   perplexity:  386.53668212890625 \n",
            "\t\tcommit_loss:  0.016612134873867035   codebook loss:  0.06644853949546814   total_loss:  0.08947999030351639\n",
            "epoch: 8   step: 201   recon_loss: 0.006658304017037153   perplexity:  389.0997314453125 \n",
            "\t\tcommit_loss:  0.01668119803071022   codebook loss:  0.06672479212284088   total_loss:  0.09006429463624954\n",
            "epoch: 8   step: 301   recon_loss: 0.006831903476268053   perplexity:  397.91180419921875 \n",
            "\t\tcommit_loss:  0.017282282933592796   codebook loss:  0.06912913173437119   total_loss:  0.0932433158159256\n",
            "epoch: 8   step: 401   recon_loss: 0.007087410427629948   perplexity:  393.06622314453125 \n",
            "\t\tcommit_loss:  0.017537852749228477   codebook loss:  0.07015141099691391   total_loss:  0.09477667510509491\n",
            "epoch: 9   step: 1   recon_loss: 0.006824538577347994   perplexity:  387.512939453125 \n",
            "\t\tcommit_loss:  0.017004476860165596   codebook loss:  0.06801790744066238   total_loss:  0.09184692054986954\n",
            "epoch: 9   step: 101   recon_loss: 0.007162982597947121   perplexity:  410.61767578125 \n",
            "\t\tcommit_loss:  0.017929736524820328   codebook loss:  0.07171894609928131   total_loss:  0.09681166708469391\n",
            "epoch: 9   step: 201   recon_loss: 0.007038027048110962   perplexity:  402.255126953125 \n",
            "\t\tcommit_loss:  0.01776435226202011   codebook loss:  0.07105740904808044   total_loss:  0.09585978835821152\n",
            "epoch: 9   step: 301   recon_loss: 0.007178544998168945   perplexity:  402.72320556640625 \n",
            "\t\tcommit_loss:  0.01822691597044468   codebook loss:  0.07290766388177872   total_loss:  0.09831312298774719\n",
            "epoch: 9   step: 401   recon_loss: 0.006823400035500526   perplexity:  406.0932312011719 \n",
            "\t\tcommit_loss:  0.017666514962911606   codebook loss:  0.07066605985164642   total_loss:  0.0951559767127037\n",
            "epoch: 10   step: 1   recon_loss: 0.006623711436986923   perplexity:  403.1853332519531 \n",
            "\t\tcommit_loss:  0.017114443704485893   codebook loss:  0.06845777481794357   total_loss:  0.09219592809677124\n",
            "epoch: 10   step: 101   recon_loss: 0.006717073731124401   perplexity:  405.5914306640625 \n",
            "\t\tcommit_loss:  0.017380034551024437   codebook loss:  0.06952013820409775   total_loss:  0.09361724555492401\n",
            "epoch: 10   step: 201   recon_loss: 0.006857970729470253   perplexity:  404.5493469238281 \n",
            "\t\tcommit_loss:  0.01764572598040104   codebook loss:  0.07058290392160416   total_loss:  0.09508660435676575\n",
            "epoch: 10   step: 301   recon_loss: 0.006212058011442423   perplexity:  402.35333251953125 \n",
            "\t\tcommit_loss:  0.016458477824926376   codebook loss:  0.0658339112997055   total_loss:  0.08850444853305817\n",
            "epoch: 10   step: 401   recon_loss: 0.006424116902053356   perplexity:  389.0366516113281 \n",
            "\t\tcommit_loss:  0.016284801065921783   codebook loss:  0.06513920426368713   total_loss:  0.08784812688827515\n",
            "epoch: 11   step: 1   recon_loss: 0.00674659525975585   perplexity:  392.0254821777344 \n",
            "\t\tcommit_loss:  0.017478231340646744   codebook loss:  0.06991292536258698   total_loss:  0.0941377505660057\n",
            "epoch: 11   step: 101   recon_loss: 0.006528513040393591   perplexity:  400.6605224609375 \n",
            "\t\tcommit_loss:  0.017616311088204384   codebook loss:  0.07046524435281754   total_loss:  0.0946100652217865\n",
            "epoch: 11   step: 201   recon_loss: 0.006464989855885506   perplexity:  386.9206237792969 \n",
            "\t\tcommit_loss:  0.01651434786617756   codebook loss:  0.06605739146471024   total_loss:  0.0890367329120636\n"
          ]
        }
      ],
      "source": [
        "print(\"Start training VQ-VAE...\")\n",
        "model.train()\n",
        "\n",
        "tracked_loss = []\n",
        "tracked_perplexity = []\n",
        "tracked_recon_loss = []\n",
        "tracked_codebook_loss = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    overall_loss = 0\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, commitment_loss, codebook_loss, perplexity = model(x)\n",
        "        recon_loss = mse_loss(x_hat, x)\n",
        "\n",
        "        loss =  recon_loss + commitment_loss + codebook_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % print_step == 0:\n",
        "            print(\"epoch:\", epoch + 1, \"  step:\", batch_idx + 1, \"  recon_loss:\", recon_loss.item(), \"  perplexity: \", perplexity.item(),\n",
        "              \"\\n\\t\\tcommit_loss: \", commitment_loss.item(), \"  codebook loss: \", codebook_loss.item(), \"  total_loss: \", loss.item())\n",
        "\n",
        "    tracked_loss.append(loss.item())\n",
        "    tracked_perplexity.append(perplexity.item())\n",
        "    tracked_recon_loss.append(recon_loss.item())\n",
        "    tracked_codebook_loss.append(codebook_loss.item())\n",
        "\n",
        "    save_checkpoint(model, tracked_loss, tracked_perplexity, tracked_recon_loss, tracked_codebook_loss, filename=\"VQ_VAE_128.pth.tar\")\n",
        "\n",
        "print(\"Finish!!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('VQ_VAE_128.pth.tar')\n"
      ],
      "metadata": {
        "id": "pK3a0Uw1RdYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R_IFjVUqR0q7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bbad5c04323042a19364135081b2e440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf83620613d4dedafdfdd8a6cf9d56f",
              "IPY_MODEL_e23f0a51466e4e55ac69ca72d05307a1",
              "IPY_MODEL_4d0ef1f8c21a4f8394d54a831f83063b"
            ],
            "layout": "IPY_MODEL_365cd66714f5460398f3493d08cf1e2e"
          }
        },
        "cbf83620613d4dedafdfdd8a6cf9d56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a33937380e6b44cf8a05a838dbc2ab1b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ccaf82b0e3049ed8a8eef14c7001203",
            "value": " 50%"
          }
        },
        "e23f0a51466e4e55ac69ca72d05307a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a93c93e1a54852a4986548947ba2eb",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e311b0aa5e0849efbeb1481155d2a7f8",
            "value": 10
          }
        },
        "4d0ef1f8c21a4f8394d54a831f83063b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e760c100af4eaab2f66641f3a51b08",
            "placeholder": "​",
            "style": "IPY_MODEL_b4dd2aa1d3ac47c2a31925112289697b",
            "value": " 10/20 [2:46:32&lt;2:45:05, 990.59s/it]"
          }
        },
        "365cd66714f5460398f3493d08cf1e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33937380e6b44cf8a05a838dbc2ab1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccaf82b0e3049ed8a8eef14c7001203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a93c93e1a54852a4986548947ba2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e311b0aa5e0849efbeb1481155d2a7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33e760c100af4eaab2f66641f3a51b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4dd2aa1d3ac47c2a31925112289697b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}